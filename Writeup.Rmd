---
title: "PML Project"
author: "Sanjay Deshpande"
date: "Sunday, March 22, 2015"
output: html_document
---

#Executive Summary

In this report we'll develop an algorithm to classify the way an exercise is done by using accelerometer variables as predictors. We develop a model based on k-nearest neighbour algorithm(method) using PCA preProcess.  The accuracy is evaluated to be 96%. While the other algorithms could have been explored, we thought 96% is good enough conformance and any thing in access of it might suffer from over fitting the data.


##Reading data and loading libraries

First we'll read the test and training data. We have to make a validation partition from the training data.

```{r}
library(caret)
traindata<-read.csv("pml-training.csv")
inTrain <- createDataPartition( traindata$classe, p=0.65, list=FALSE);
training <- traindata[ inTrain,];
validation <- traindata[ -inTrain,];
testdata<-read.csv("pml-testing.csv")
```

Now, we'll look at the data we have read. As we don't know how many predictors we have, we'll first make a count of columns.

```{r}
length(names(traindata))
```


We notice a high number of predictors, so we could use a way to reduce them.


#Cleaning data

An obvious way is to remove all the columns that have NAs and blank strings.This would help in better statistical estimations

```{r}
training2 <- training[,  !apply( is.na(training), 2,any)]
training2 <- training2[, !apply( training2=="",   2,any)]
length(names(training2))
```

#Models creation & Accuracy
Making use of 60 predictors available, we will try to fit themin to a model. We choose k-nearest neightbour method to determine the closest neighbours of the each prediction classes. We will also do preprocessing using PCA


```{r}
model1<-train(classe~.,data=training2, method = "knn",preProcess="pca")
```
#Validate
Now we have built a model based on the cleaned up data. At this stage we can cross validate whether the model is appropriate solution or not by predicting the validation data. We can also calculate sample error.

```{r}
confusionMatrix( predict( model1, validation ), validation$classe );
```
#Conclusion
We have demonstrated that the knn method works well for this classification problem.We achieve about 96% accuracy in our prediction. While it is possible to build other types of models, targeting to improve accuracy beyond the point reached here could be a mistake resulting in over fitting the data. 
